{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDQN эталонная версия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт среды "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "from environment import Env\n",
    "e = Env( dim = (30,30) , countOBS = 8, sizeOBS = 6,\n",
    "        seed=24, str_x_y=(0,0), trg_x_y=(29,29),\n",
    "        learning = True, gamma=0.995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт агаента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DDQN_endV import DDQN\n",
    "Agent = DDQN(input_dimention = (30,30,3), num_actions = 8,\n",
    "            gamma = 0.995, max_experiences = 100000, min_experiences = 150,\n",
    "            batch_size = 75, lr = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попытка играть и обучать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для одной сессии\n",
    "def play_game_1(e, Agent, epsilon,d):\n",
    "\n",
    "\n",
    "    e.gen_points(t_dist = d)\n",
    "    e.learning_restart_this_game() \n",
    "    \n",
    "    n_steps=0\n",
    "    \n",
    "    done = False\n",
    "    scene = e.img\n",
    "    \n",
    "    while not done:\n",
    "        action = Agent.get_action(scene[None], epsilon)                              #Агент выюирает действие  \n",
    "        prev_scene = scene\n",
    "\n",
    "        scene, reward, game_revord , done = e.learning_step(direction = action)      #Совершение действия в среде\n",
    "#         e.update_map()\n",
    "        \n",
    "        exp = {'s': prev_scene, 'a': action, 'r': reward, 's2': scene, 'done': done} #делаем семпл для exp replay\n",
    "        \n",
    "        Agent.add_experience(exp)                                                    #добавляем семпл\n",
    "        Agent.train()                                                                #Обучение агента\n",
    "        \n",
    "        n_steps = n_steps + 1\n",
    "        \n",
    "        if n_steps >= 150: \n",
    "            break\n",
    "        \n",
    "        \n",
    "    return game_revord                                                               #Возвращаем реворд за игру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для одной сессии\n",
    "def play_game_2(e, Agent, epsilon,d):\n",
    "\n",
    "    e.update_scene(d)\n",
    "    e.learning_restart_this_game()\n",
    "    \n",
    "    n_steps=0\n",
    "    \n",
    "    done = False\n",
    "    scene = e.img\n",
    "    \n",
    "    while not done:\n",
    "        action = Agent.get_action(scene[None], epsilon)                              #Агент выюирает действие  \n",
    "        prev_scene = scene\n",
    "\n",
    "        scene, reward, game_revord , done = e.learning_step(direction = action)      #Совершение действия в среде\n",
    "#         e.update_map()\n",
    "        \n",
    "        exp = {'s': prev_scene, 'a': action, 'r': reward, 's2': scene, 'done': done} #делаем семпл для exp replay\n",
    "        \n",
    "        Agent.add_experience(exp)                                                    #добавляем семпл\n",
    "        Agent.train()                                                                #Обучение агента\n",
    "        \n",
    "        n_steps = n_steps + 1\n",
    "        \n",
    "        if n_steps >= 150: \n",
    "            break\n",
    "        \n",
    "        \n",
    "    return game_revord                                                               #Возвращаем реворд за игру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Несколько сессий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# epsilon - начальное значение e-greedy значения\n",
    "# decay - шаг уменьшения epsilon\n",
    "# min_epsilon - значение epsilon, ниже которого умешьшение не будет производиться\n",
    "# game_revord - реворд за одну игру\n",
    "# n - номер итерации(кол-во сыгранных игр)\n",
    "# All_game_revord - список со значением ревордов за каждую игру\n",
    "\n",
    "\n",
    "epsilon = 0.99\n",
    "decay = 0.99\n",
    "min_epsilon = 0.001\n",
    "All_game_revord = []\n",
    "d=1\n",
    "\n",
    "Avg = 0\n",
    "n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while(d != 44 ):                                        \n",
    "#     epsilon = max(min_epsilon, epsilon * decay)                    # Уменьшаем эпсилон\n",
    "    \n",
    "#     game_revord = play_game_1(e, Agent, epsilon,d)                     # Играем игру\n",
    "\n",
    "#     if Avg>5:\n",
    "#         d = d + 1\n",
    "#         All_game_revord=[-100]\n",
    "    \n",
    "#     All_game_revord.append(game_revord)                            # Считаем средний реворд\n",
    "#     Avg = sum(All_game_revord)/len(All_game_revord)\n",
    "    \n",
    "#     if len(All_game_revord)>200:                                   # Если список больше заданного значения, обновляем его\n",
    "#         All_game_revord=[sum(All_game_revord)/len(All_game_revord)]\n",
    "#     clear_output()\n",
    "    \n",
    "    \n",
    "#     print('Episode: %s \\n'\n",
    "#           'distanse: %s \\n'\n",
    "#           'eps: %s \\n'\n",
    "#           'Game 1 reward: %s \\n'\n",
    "#           'avg reward: %s '\n",
    "#           % (n,\n",
    "#              d,\n",
    "#              epsilon,\n",
    "#              game_revord,\n",
    "#              Avg ))\n",
    "    \n",
    "#     n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 200 \n",
      "distanse: 1 \n",
      "eps: 0.1313134793282883 \n",
      "Game 2 reward: 10 \n",
      "avg reward: 3.433108207263763 \n"
     ]
    }
   ],
   "source": [
    "All_game_revord = [-100]\n",
    "d=1\n",
    "Avg = 0\n",
    "n=0\n",
    "    \n",
    "while(True):                                        \n",
    "    epsilon = max(min_epsilon, epsilon * decay)                    # Уменьшаем эпсилон\n",
    "    \n",
    "    game_revord = play_game_1(e, Agent, epsilon,d)                     # Играем игру\n",
    "\n",
    "    if Avg>5:\n",
    "        d = d + 1\n",
    "        All_game_revord=[-100]\n",
    "    \n",
    "    All_game_revord.append(game_revord)                            # Считаем средний реворд\n",
    "    Avg = sum(All_game_revord)/len(All_game_revord)\n",
    "    \n",
    "    if len(All_game_revord)>200:                                   # Если список больше заданного значения, обновляем его\n",
    "        All_game_revord=[sum(All_game_revord)/len(All_game_revord)]\n",
    "    clear_output()\n",
    "    \n",
    "    \n",
    "    print('Episode: %s \\n'\n",
    "          'distanse: %s \\n'\n",
    "          'eps: %s \\n'\n",
    "          'Game 2 reward: %s \\n'\n",
    "          'avg reward: %s '\n",
    "          % (n,\n",
    "             d,\n",
    "             epsilon,\n",
    "             game_revord,\n",
    "             Avg ))\n",
    "    \n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agent.save_train_net('train_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agent.save_target_net('trget_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
